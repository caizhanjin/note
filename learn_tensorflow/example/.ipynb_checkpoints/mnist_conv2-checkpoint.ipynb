{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "55000\n",
      "5000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "例子为MNIST，对手写图片进行分类。\n",
    "《tensorflow实战》第五章实例\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "print(mnist.train.num_examples)\n",
    "print(mnist.validation.num_examples)\n",
    "print(mnist.test.num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 784)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# 从集合中取出数据\n",
    "xs, ys = mnist.train.next_batch(batch_size)\n",
    "print(xs.shape)\n",
    "print(ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_node = 784 # 图片像素\n",
    "output_node = 10 # 10个数字\n",
    "\n",
    "layer1_node = 500 # 隐藏层节点数\n",
    "\n",
    "batch_size = 100\n",
    "training_steps = 30000\n",
    "\n",
    "learning_rate_base = 0.8 # 基础学习率\n",
    "learning_rate_decay = 0.99 # 学习率衰减率\n",
    "regularization_rate = 0.0001 # 描述模型复杂度的正则化项在损失函数中的系数\n",
    "moving_average_decay = 0.99 # 滑动平均衰减率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型封装\n",
    "def inference(input_tensor, avg_class, weights1, biases1, weights2, biases2):\n",
    "    # 如果没有提供滑动平均类，就直接使用参数\n",
    "    if avg_class == None:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1)\n",
    "        return tf.matmul(layer1, weights2) + biases2\n",
    "    else:\n",
    "        layer1 = tf.nn.relu(\n",
    "            tf.matmul(input_tensor, avg_class.average(weights1)) + \n",
    "            avg_class.average(biases1))\n",
    "        return tf.matmul(\n",
    "            layer1, avg_class.average(weights2)) + avg_class.average(biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"训练模型过程\"\"\"\n",
    "x = tf.placeholder(tf.float32, [None, input_node], name='x_input')\n",
    "y_ = tf.placeholder(tf.float32, [None, output_node], name='y_input')\n",
    "\n",
    "# 隐藏层参数\n",
    "weights1 = tf.Variable(\n",
    "    tf.truncated_normal([input_node, layer1_node], stddev=0.1))\n",
    "biases1 = tf.Variable(tf.constant(0.1, shape=[layer1_node]))\n",
    "# 输出层参数\n",
    "weights2 = tf.Variable(\n",
    "    tf.truncated_normal([layer1_node, output_node], stddev=0.1))\n",
    "biases2 = tf.Variable(tf.constant(0.1, shape=[output_node]))\n",
    "\n",
    "# 计算前向传播结果，这里不使用滑动平均值\n",
    "y = inference(x, None, weights1, biases1, weights2, biases2)\n",
    "\n",
    "# 存储训练轮数变量，不可训练参数\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "# 初始化滑动平均类\n",
    "variable_averages = tf.train.ExponentialMovingAverage(\n",
    "    moving_average_decay, global_step)\n",
    "# 在可训练的变量上使用滑动平均\n",
    "variables_averages_op = variable_averages.apply(\n",
    "    tf.trainable_variables())\n",
    "# 使用滑动平均之后的前向传播\n",
    "average_y = inference(\n",
    "    x, variable_averages, weights1, biases1, weights2, biases2)\n",
    "\n",
    "# 计算损失\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=y, labels=tf.argmax(y_, 1))\n",
    "cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# L2正则损失\n",
    "regularizer = tf.contrib.layers.l2_regularizer(regularization_rate)\n",
    "regularization = regularizer(weights1) + regularizer(weights2)\n",
    "\n",
    "# 总损失等于交叉熵和正则化和\n",
    "loss = cross_entropy_mean + regularization\n",
    "\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    learning_rate_base,\n",
    "    global_step,\n",
    "    mnist.train.num_examples / batch_size, # 走完训练数据的迭代次数\n",
    "    learning_rate_decay)\n",
    "\n",
    "# 添加优化器\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "# 计算反向网络，更新网络参数和滑动平均值\n",
    "with tf.control_dependencies([train_step, variables_averages_op]):\n",
    "    train_op = tf.no_op(name='train')\n",
    "    \n",
    "# 评估模型\n",
    "correct_prediction = tf.equal(tf.argmax(average_y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 training step(s), validation accuracy using average model is 0.0994 \n",
      "After 1000 training step(s), validation accuracy using average model is 0.9778 \n",
      "After 2000 training step(s), validation accuracy using average model is 0.9824 \n",
      "After 3000 training step(s), validation accuracy using average model is 0.9826 \n",
      "After 4000 training step(s), validation accuracy using average model is 0.9844 \n",
      "After 5000 training step(s), validation accuracy using average model is 0.9842 \n",
      "After 6000 training step(s), validation accuracy using average model is 0.9842 \n",
      "After 7000 training step(s), validation accuracy using average model is 0.9836 \n",
      "After 8000 training step(s), validation accuracy using average model is 0.984 \n",
      "After 9000 training step(s), validation accuracy using average model is 0.9842 \n",
      "After 10000 training step(s), validation accuracy using average model is 0.9842 \n",
      "After 11000 training step(s), validation accuracy using average model is 0.9838 \n",
      "After 12000 training step(s), validation accuracy using average model is 0.984 \n",
      "After 13000 training step(s), validation accuracy using average model is 0.985 \n",
      "After 14000 training step(s), validation accuracy using average model is 0.9838 \n",
      "After 15000 training step(s), validation accuracy using average model is 0.9848 \n",
      "After 16000 training step(s), validation accuracy using average model is 0.985 \n",
      "After 17000 training step(s), validation accuracy using average model is 0.9844 \n",
      "After 18000 training step(s), validation accuracy using average model is 0.9846 \n",
      "After 19000 training step(s), validation accuracy using average model is 0.9838 \n",
      "After 20000 training step(s), validation accuracy using average model is 0.9838 \n",
      "After 21000 training step(s), validation accuracy using average model is 0.9846 \n",
      "After 22000 training step(s), validation accuracy using average model is 0.984 \n",
      "After 23000 training step(s), validation accuracy using average model is 0.9846 \n",
      "After 24000 training step(s), validation accuracy using average model is 0.9842 \n",
      "After 25000 training step(s), validation accuracy using average model is 0.9846 \n",
      "After 26000 training step(s), validation accuracy using average model is 0.9846 \n",
      "After 27000 training step(s), validation accuracy using average model is 0.985 \n",
      "After 28000 training step(s), validation accuracy using average model is 0.9846 \n",
      "After 29000 training step(s), validation accuracy using average model is 0.985 \n",
      "After 30000 training step(s), test accuracy using average model is 0.984 \n"
     ]
    }
   ],
   "source": [
    "# 计算图\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    # 验证数据\n",
    "    validate_feed = {\n",
    "        x: mnist.validation.images,\n",
    "        y_: mnist.validation.labels\n",
    "    }\n",
    "    # 测试数据\n",
    "    test_feed = {\n",
    "        x: mnist.test.images,\n",
    "        y_: mnist.test.labels\n",
    "    }\n",
    "    # 开始迭代\n",
    "    for i in range(training_steps):\n",
    "        xs, ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_op, feed_dict={ x: xs, y_: ys })\n",
    "        if i%1000 == 0:\n",
    "            validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
    "            print(\"After %d training step(s), validation accuracy \"\n",
    "                  \"using average model is %g \" % (i, validate_acc))\n",
    "\n",
    "    # 训练结束，计算最终准确率\n",
    "    test_acc = sess.run(accuracy, feed_dict=test_feed)\n",
    "    print(\"After %d training step(s), test accuracy using average \"\n",
    "        \"model is %g \" % ( training_steps, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    saver.save(sess, \"./model/model.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
